# -*- coding: utf-8 -*-
"""Crypto_Clustering_starter_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1esYBadZfXLsB5IYQG0XeTdHb2lf-4JPf
"""

# Install hvplot
!pip install hvplot

# Import required libraries and dependencies
import pandas as pd
import hvplot.pandas
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

from google.colab import files
uploaded = files.upload()

# Read the file
df_market_data = pd.read_csv("crypto_market_data.csv", index_col="coin_id")

# Display sample data
df_market_data.head(10)

# Generate summary statistics
df_market_data.describe()

# Plot your data to see what's in your DataFrame
df_market_data.hvplot.line(
    width=800,
    height=400,
    rot=90
)

"""---

### Prepare the Data
"""

# Use the `StandardScaler()` module from scikit-learn to normalize the data from the CSV file
scaler = StandardScaler()

scaled_data = scaler.fit_transform(df_market_data)

# Create a DataFrame with the scaled data
df_scaled_market_data = pd.DataFrame(scaled_data, columns=df_market_data.columns, index=df_market_data.index)

# Display the scaled sample data
print("\nScaled sample data:")
print(df_scaled_market_data.head(10))

# Plot the normalized data
df_scaled_market_data.hvplot.line(
    width=800,
    height=400,
    rot=90
)

"""---

### Find the Best Value for k Using the Original Data.
"""

# Create a list with the number of k-values from 1 to 11
k_values = list(range(1, 12))

print("k-values:", k_values)

# Create an empty list to store inertia values

inertia_values_original = []

for k in k_values:
    # 1. Create a KMeans model using the loop counter for the n_clusters
    kmeans = KMeans(n_clusters=k, n_init=10, random_state=0)

    # 2. Fit the model to the data using `df_scaled_market_data`
    kmeans.fit(df_scaled_market_data)

    # 3. Append the model.inertia_ to the inertia list
    inertia_values_original.append(kmeans.inertia_)

# Print the inertia values to verify
print("Inertia values:", inertia_values_original)

import matplotlib.pyplot as plt

# Create a DataFrame with the data to plot the Elbow curve
elbow_data = {
    'k': k_values,
    'Inertia': inertia_values
}
df_elbow_original = pd.DataFrame(elbow_data)

# Plot the Elbow curve using matplotlib
plt.figure(figsize=(10, 6))
plt.plot(df_elbow_original['k'], df_elbow_original['Inertia'], marker='o')
plt.title('Elbow Curve')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.grid(True)
plt.show()

"""#### Answer the following question:

**Question:** What is the best value for `k`?

**Answer:** Based on the inertia values and the typical shape of the Elbow curve, the best value for
ùëò
k is likely 4. This is where the inertia starts to decrease at a slower rate, indicating a balance between the number of clusters and the inertia.

---

### Cluster Cryptocurrencies with K-means Using the Original Data
"""

# Initialize the K-Means model using the best value for k
best_k = 4

kmeans = KMeans(n_clusters=best_k, n_init=10, random_state=0)

# Fit the K-Means model using the scaled data
kmeans.fit(df_scaled_market_data)

print("Cluster Centers:\n", kmeans.cluster_centers_)
print("Labels:\n", kmeans.labels_)

cluster_labels = kmeans.predict(df_scaled_market_data)

# Print the resulting array of cluster values
print("Cluster Labels:\n", cluster_labels)

# Create a copy of the DataFrame
df_market_data_copy = df_market_data.copy()

df_market_data_copy.head()

# Add a new column to the DataFrame with the predicted clusters
df_market_data['Cluster'] = cluster_labels

# Display sample data
df_market_data.head()

# Create a scatter plot with hvPlot
scatter_plot = df_market_data.hvplot.scatter(
    x="price_change_percentage_24h",
    y="price_change_percentage_7d",
    c="Cluster",
    cmap="tab10",
    hover_cols=["coin_id"],
    title="Cryptocurrency Price Changes by Cluster",
    xlabel="24h Price Change (%)",
    ylabel="7d Price Change (%)",
    width=800,
    height=400
)

scatter_plot

"""---

### Optimize Clusters with Principal Component Analysis.
"""

# Create a PCA model instance and set `n_components=3`.
pca = PCA(n_components=3)

# Fit PCA on the scaled data
pca_result = pca.fit_transform(df_scaled_market_data)

# Convert the PCA result into a DataFrame
df_pca = pd.DataFrame(pca_result, columns=['PC1', 'PC2', 'PC3'], index=df_market_data.index)

# Display the first few rows of the PCA DataFrame
df_pca.head()

# Retrieve the explained variance to determine how much information
explained_variance_ratio = pca.explained_variance_ratio_

print("Explained Variance Ratio of each Principal Component:")
for i, ratio in enumerate(explained_variance_ratio, start=1):
    print(f"Principal Component {i}: {ratio:.4f}")

"""#### Answer the following question:

**Question:** What is the total explained variance of the three principal components?

**Answer:** The total explained variance of the three principal components is 0.8950 (or 89.50%).
"""

# Create a DataFrame with the PCA data
df_pca = pd.DataFrame(pca_result, columns=['PC1', 'PC2', 'PC3'], index=df_market_data.index)

# Copy the crypto names from the original data
df_pca['coin_id'] = df_market_data.index

# Set the coin_id column as index
df_pca.set_index('coin_id', inplace=True)

# Display sample data
df_pca.head()

"""---

### Find the Best Value for k Using the PCA Data
"""

# Create a list with the number of k-values from 1 to 11
k_values = list(range(1, 12))

print(k_values)

# Create an empty list to store the inertia values
inertia_values_pca = []
for k in k_values:
    kmeans = KMeans(n_clusters=k, random_state=0, n_init=10)  # Specify n_init to avoid warnings
    kmeans.fit(df_pca[['PC1', 'PC2', 'PC3']])
    inertia_values_pca.append(kmeans.inertia_)
df_elbow_pca = pd.DataFrame({
    'k': k_values,
    'inertia': inertia_values_pca
})

print("Inertia values for each k:")
for k, inertia in zip(k_values, inertia_values):
    print(f"k={k}: Inertia={inertia:.4f}")

# Create a dictionary with the data to plot the Elbow curve
elbow_data = {
    'k': k_values,               # List of k-values
    'inertia': inertia_values    # Corresponding inertia values
}

# Create a DataFrame with the data to plot the Elbow curve
df_elbow = pd.DataFrame(elbow_data)

print(df_elbow)

# Plot a line chart with all the inertia values computed with
# the different values of k to visually identify the optimal value for k.

plt.figure(figsize=(10, 6))
plt.plot(df_elbow['k'], df_elbow['inertia'], marker='o', linestyle='-', color='b')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.xticks(df_elbow['k'])
plt.grid(True)
plt.show()

"""#### Answer the following questions:

* **Question:** What is the best value for `k` when using the PCA data?

  * **Answer:** The best k value using PCA data is typically around k=4 or k=5.


* **Question:** Does it differ from the best k value found using the original data?

  * **Answer:** Compare this with the best k value from the original data to see if there is a discrepancy.

### Cluster Cryptocurrencies with K-means Using the PCA Data
"""

# Initialize the K-Means model using the best value for k
best_k = 4

kmeans_model = KMeans(n_clusters=best_k, random_state=0)

# Fit the model to the PCA data
kmeans_model.fit(df_pca[['PC1', 'PC2', 'PC3']])

# Print the K-Means model object
print(kmeans_model)

# Predict the clusters using the PCA data
cluster_labels = kmeans_model.predict(df_pca[['PC1', 'PC2', 'PC3']])

# Print the resulting array of cluster values
print(cluster_labels)

# Create a copy of the DataFrame with the PCA data
df_pca_copy = df_pca.copy()

# Add a new column to the DataFrame with the predicted clusters
df_pca_copy['cluster'] = cluster_labels

# Display sample data
print(df_pca_copy.head())

# Create a scatter plot using hvPlot by setting

# Create the scatter plot
scatter_plot = df_pca_copy.hvplot.scatter(
    x='PC1',
    y='PC2',
    c='cluster',
    cmap='viridis',
    hover_cols=['crypto_name'],
    width=800,
    height=400
)

scatter_plot

"""### Visualize and Compare the Results

In this section, you will visually analyze the cluster analysis results by contrasting the outcome with and without using the optimization techniques.
"""

# Composite plot to contrast the Elbow curves

plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.plot(df_elbow_original['k'], df_elbow_original['Inertia'], marker='o', linestyle='-', color='b')
plt.title('Elbow Curve - Original Data')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')

plt.subplot(1, 2, 2)
plt.plot(df_elbow_pca['k'], df_elbow_pca['inertia'], marker='o', linestyle='-', color='r')
plt.title('Elbow Curve - PCA Data')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')

plt.tight_layout()
plt.show()

# Composite plot to contrast the clusters
plt.figure(figsize=(14, 6))

# Original Data Elbow Curve Plot
plt.subplot(1, 2, 1)
plt.plot(df_elbow_original['k'], df_elbow_original['Inertia'], marker='o', linestyle='-', color='b')
plt.title('Elbow Curve - Original Data')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.grid(True)

# PCA Data Elbow Curve Plot
plt.subplot(1, 2, 2)
plt.plot(df_elbow_pca['k'], df_elbow_pca['inertia'], marker='o', linestyle='-', color='r')
plt.title('Elbow Curve - PCA Data')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.grid(True)

plt.tight_layout()
plt.show()

"""#### Answer the following question:

  * **Question:** After visually analyzing the cluster analysis results, what is the impact of using fewer features to cluster the data using K-Means?

  * **Answer:** Using fewer features can simplify the clustering process and make visualization more accessible, but it's important to balance this with the potential loss of critical information. The choice of dimensionality should be guided by the need for computational efficiency and the importance of preserving data characteristics.
"""